#### 5.6.1 Scoring Your Own Demo

Most Sales Engineers measure the success of a demonstration by a single metric: Did the prospect seem happy at the end?

This is a terrible metric. An executive who is completely disengaged and has no intention of buying your software will often smile, nod politely, say "This looks very powerful," and hang up, solely to avoid conflict. A happy prospect does not equal a good demo.

A Master-Class SE evaluates their own performance ruthlessley, using an objective scoring rubric based on deal advancement, not applause.

**1. The "Talk-Time" Ratio**
A feature-dumping Harbor Tour usually features an SE talking for 45 straight minutes while the prospect stays on mute. 
*Self-Scoring:* If your voice accounts for more than 60% of the total meeting time, you failed the demo. You lectured instead of consulting. A score of 10/10 requires the prospect to be speaking, verifying, or questioning for at least 40% of the call. 
*Action:* Use tools like Gong or Chorus to objectively output your talk-time ratio. Do not trust your gut feeling.

**2. The "Discovery-to-Click" Mapping**
Did you show features because they exist, or because they were demanded by the prospect's pain?
*Self-Scoring:* Look at your agenda. For every single distinct screen or module you showed, can you explicitly name the specific pain point from the discovery call that required it? If you demoed the "Reporting Engine" but the prospect never mentioned reporting as a problem during discovery, deduct points. You were wasting their time.

**3. The Objection Density**
A demo with zero objections is not a perfect demo; it is a demo given to a prospect who does not care. If a prospect is seriously considering ripping out their legacy system to install yours, they will be terrified of the implementation risks. They *should* be attacking your architecture.
*Self-Scoring:* Did you receive at least two highly specific, aggressive technical pushbacks? If yes, the prospect was mentally engaged in the reality of buying the software. If no, the prospect was watching TV. 

**4. The "C.R.A.F.T." Execution Rate**
Refer back to Section 5.1.2 (Current State, Ramifications, Alternative State, Financial Impact, Tie-Down). 
*Self-Scoring:* Did you execute the full C.R.A.F.T. methodology on your core "Aha!" moment? Did you actually quantify the Financial Impact of the click, or did you just show the click and move on? Did you secure a verbal "Yes" during the Tie-Down? 

**5. The Defined Next Step**
The ultimate metric of a successful demonstration is not applause; it is calendar velocity.
*Self-Scoring:* Did the meeting end with "We'll follow up next week," or did it end with "We need our security team to review your SOC2 report by Thursday, and we will reconvene on Friday at 10 AM to scope the POC"? If there is no specific, calendar-bound technical next step owned by the prospect, the demo failed to create urgency.

> **War Story:** An SE recorded his first executive demo and scored it using Gong. He felt great about the call. The CTO had praised the UI. But when the SE reviewed the tape using the scoring rubric, he realized his talk-time was 82%. He had steamrolled the CTO. He also realized he had shown the advanced RBAC settings for 12 minutesâ€”a feature the CTO never asked for. He scored himself a 4/10. He forced himself to practice the C.R.A.F.T. framework for two hours that weekend until he could execute the 5-minute Aha! rule flawlessly. On his next CTO demo, his talk time dropped to 51%, and the CTO signed the technical validation document on the call.

> **Failure Mode:** "The Happy Ears" SE. This SE tells their manager that every single demo "went perfectly, the client loved it," simply because the prospect was polite. They use subjective feelings instead of objective metrics, and are continually shocked when their "perfect" demos result in deals going dark a week later.

**Interview Angle:**
"How do you measure if a software demonstration was successful?"
A strong answer avoids mentioning the prospect's mood. "I score my demos objectively based on talk-time ratio, Objection Density (did they care enough to challenge me?), and whether I successfully executed the C.R.A.F.T. framework to tie the clicks explicitly back to the financial impact we uncovered in discovery."

ðŸŸ¡ **Senior-Level** â€” Applause is for theater. Urgency is for presales. Score your demos on urgency.

---
